{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZTHqkI6yKpAx"
   },
   "source": [
    "# モデルの学習\n",
    "本単元では、前回作成した**MLPモデルを学習させる過程**について説明する。  \n",
    "具体的には、学習に使う`train()`関数とテストに使う`test()`関数の実装だ。  \n",
    "\n",
    "## この単元の目標\n",
    "- MLPモデルを学習できるようになろう。\n",
    "- MLPモデルをテストできるようになろう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wK8vNgAaVv3_"
   },
   "source": [
    "## 0. 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZJTRwduamDI"
   },
   "outputs": [],
   "source": [
    "# 本章で使うモジュール\n",
    "from torch import utils\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqQh5xZsPPPY"
   },
   "source": [
    "### 【MNISTデータセット】\n",
    "まずは、学習に使うデータセットを準備しよう。  \n",
    "**MNISTデータセット**は、**画像データと正解ラベルがセットになったクラス分類のための教師ありデータセット**だ。  \n",
    "画像には**0〜9の数字**が書かれ、正解ラベルはその画像が表している1桁の数字であるため、**10クラスの分類**である。  \n",
    "1枚の画像の形状は、色が白黒で28\\*28画素なので、その**形状は`(28, 28, 1)`**だ。  \n",
    "\n",
    "pytorchには、データセットがライブラリとしていくつか用意（実際にはダウンロードする関数）されており、  \n",
    "MNISTもその1つだ。  \n",
    "以下のコードを実行すれば、データセットをダウンロードする事ができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "## こうやってダウンロードして使うことができるよ\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_loader = utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "test_loader = utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XowdNPCCYfGF"
   },
   "source": [
    "### 【モデルの準備】\n",
    "次に、学習を行うためのモデルを準備しよう。  \n",
    "行うタスクは、**「28*28画素の白黒画像を10クラス分類する」**事なので、  \n",
    "入力ノードの数は784（=28*28）個で、出力ノードの数は10個で良いだろう。\n",
    "\n",
    "よって、以下の条件のMLPモデルをクラスとして定義する。  \n",
    "- 「入力層、中間層、出力層」のノードの数が「784（=28×28）、512、10」\n",
    "- 中間層の出力に活性化関数`relu()`を適用\n",
    "- 損失関数は`MSELoss()`\n",
    "- 最適化関数は`Adam()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jRPWplc-ZGYF"
   },
   "outputs": [],
   "source": [
    "class mlp_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.parameters())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DYWI7-a2V7yq"
   },
   "source": [
    "## 1. train()関数の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZpnvycGkfJI"
   },
   "source": [
    "それでは、**`train()`関数の実装**を行っていこう。  \n",
    "大枠は、「実用画像データ処理コース」で実装したものと同じだが、下記の点で異なる。\n",
    "- 2次元の画像であるテンソルを1次元のテンソルに変換する。\n",
    "- 損失を求めるために正解データをone-hotベクトル化する。\n",
    "\n",
    "MLPはその構造上、**2次元以上である画像データをその形状のまま入力として受け取る事ができない。**  \n",
    "よって、画像を行や列で区切るなどして**1次元のテンソルに変換してからモデルに入力**する。  \n",
    "今回は、形状変形のために`reshape()`を使おう。\n",
    "\n",
    "また、  \n",
    "モデルの出力は**各クラスの予測確率に相関したベクトル**であるのに対し、**正解ラベルはクラス名（0~9の値）**であるため、  \n",
    "そのままではMSEを計算する事ができない。  \n",
    "そこで、正解ラベルを「one-hotベクトルに変換」することで、モデルの予測結果との損失計算を可能にする。  \n",
    "【one-hotベクトル化の例】\n",
    "- 正解ラベル「1」 → `[0,1,0,0,0,0,0,0,0,0]` （=「1」である確率が1の確率ベクトル）\n",
    "- 正解ラベル「7」 → `[0,0,0,0,0,0,0,1,0,0]` （=「7」である確率が1の確率ベクトル）\n",
    "\n",
    "以上のことを踏まえて、  \n",
    "例題を見ながら`train()`関数の実装方法を確認しよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CB7fXVCnwRnd"
   },
   "source": [
    "【例題】 `train()`関数を実装する。  \n",
    "まずは、`train()`関数の全体像を思い出そう。  \n",
    "`train()`関数は、引数に`model`（学習するモデル）と`train_loader`（学習データローダ）を受け取り、  \n",
    "`train_loader`を「バッチ=ある程度の数のデータのまとまり」ごとにループさせて学習を行う。  \n",
    "この1ループは、次の流れで進む。\n",
    "1. バッチごとのデータをモデルへ順伝播させる\n",
    "2. 正解ラベルと比較して損失を計算する\n",
    "3. 損失から最適化を行う\n",
    "4. 次のバッチへ\n",
    "\n",
    "今回は、これに加えて**「画像データの1次元化」**と**「正解ラベルのone-hotベクトル化」**を忘れないようにしよう。  \n",
    "one-hotベクトル化には`torch.eye()`が使える。  \n",
    "`torch.eye(クラス数)[バッチごとのデータ]`と記述することで、`バッチごとのデータ`の1要素に対してone-hotベクトル化を適用する事ができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22EuWFr4WQGR"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    # 今は学習時であることを明示するコード\n",
    "    model.train()\n",
    "    for batch_imgs, batch_labels in train_loader:\n",
    "        ## 画像データを1次元に変換\n",
    "        batch_imgs = batch_imgs.reshape(-1, 28*28*1)\n",
    "        ## 正解ラベルをone-hotベクトルへ変換\n",
    "        labels = torch.eye(10)[batch_labels]\n",
    "\n",
    "        ## 順伝播\n",
    "        outputs = model(batch_imgs)\n",
    "        ## 勾配を初期化（前回のループ時の勾配を削除）\n",
    "        model.optimizer.zero_grad()\n",
    "        ## 損失を計算\n",
    "        loss = model.criterion(outputs, labels)\n",
    "        ## 逆伝播で勾配を計算\n",
    "        loss.backward()\n",
    "        ## 最適化\n",
    "        model.optimizer.step()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTrJa_Bn_eOn"
   },
   "source": [
    "以上のコードでは、学習自体はできるが学習過程を確認する事ができないので、  \n",
    "「正答率」と「損失の合計」を出力できるように、以下のように改良する。  \n",
    "追記部分は、ほとんどが「実用画像データ処理」を流用したものなので、コードを読めば理解できるだろう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8euG-MK98LR"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    # 今は学習時であることを明示するコード\n",
    "    model.train()\n",
    "\n",
    "    ### 追記部分1 ###\n",
    "    # 正しい予測数、損失の合計、全体のデータ数を数えるカウンターの0初期化\n",
    "    total_correct = 0\n",
    "    total_loss = 0\n",
    "    total_data_len = 0\n",
    "    ### ###\n",
    "\n",
    "    for batch_imgs, batch_labels in train_loader:\n",
    "        ## 2次元データを1次元に変換\n",
    "        batch_imgs = batch_imgs.reshape(-1, 28*28*1)\n",
    "        ## 正解ラベルをone-hotベクトルへ変換\n",
    "        labels = torch.eye(10)[batch_labels]\n",
    "\n",
    "        ## 順伝播\n",
    "        outputs = model(batch_imgs)\n",
    "        ## 勾配を初期化（前回のループ時の勾配を削除）\n",
    "        model.optimizer.zero_grad()\n",
    "        ## 損失を計算\n",
    "        loss = model.criterion(outputs, labels)\n",
    "        ## 逆伝播で勾配を計算\n",
    "        loss.backward()\n",
    "        ## 最適化\n",
    "        model.optimizer.step()\n",
    "        \n",
    "        ### 追記部分2 ###\n",
    "        # 正答率を求める\n",
    "        _, pred_labels = torch.max(outputs, 1)\n",
    "        batch_size = len(batch_labels)\n",
    "        for i in range(batch_size):\n",
    "            total_data_len += 1\n",
    "            if pred_labels[i] == batch_labels[i]:\n",
    "                total_correct += 1\n",
    "        total_loss += loss.item()\n",
    "    accuracy = total_correct/total_data_len*100\n",
    "    loss = total_loss/total_data_len\n",
    "    return accuracy, loss\n",
    "    ### ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14823,
     "status": "ok",
     "timestamp": 1590400456477,
     "user": {
      "displayName": "hiro ino",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GihSdoqMmcaSzIVlnJIdtCgZPtPBEFqr0Y3_Cyp=s64",
      "userId": "16665494520159410568"
     },
     "user_tz": -540
    },
    "id": "wDSSBkxZZPu0",
    "outputId": "5e661795-a138-4396-8757-fa87f5dbd239"
   },
   "outputs": [],
   "source": [
    "# モデルを宣言する\n",
    "model = mlp_net()\n",
    "\n",
    "# 学習させ、その結果を表示する\n",
    "acc, loss = train(model, train_loader)\n",
    "print(f'正答率: {acc}, 損失: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCP1JwtARCI_"
   },
   "source": [
    "- ```\n",
    "正答率： {95.0前後}, 損失: {0.0002前後}\n",
    "```\n",
    "と表示されていれば成功だ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRTxU6U9QPgR"
   },
   "source": [
    "【問題】 新しいMLPモデル`mlp_net_2()`をクラスとして定義して、学習、結果を例題と同様に表示しよう。  \n",
    "ただし、以下の条件にあるようにハイパーパラメータを指定すること。\n",
    "- 宣言する`mlp_net_2()`のインスタンス名（変数名）は`model_2`とすること\n",
    "- 中間層のノードの数を`256`にする\n",
    "- `optim.Adam()`の引数`lr`に`0.01`を指定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfXBJ_IGRTpv"
   },
   "outputs": [],
   "source": [
    "class mlp_net_2(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.fc1 = nn.Linear(784, 256)\n",
    "    self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    self.criterion = nn.MSELoss()\n",
    "    self.optimizer = optim.Adam(self.parameters(), lr=0.01)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.fc2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19264,
     "status": "ok",
     "timestamp": 1590401142196,
     "user": {
      "displayName": "hiro ino",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GihSdoqMmcaSzIVlnJIdtCgZPtPBEFqr0Y3_Cyp=s64",
      "userId": "16665494520159410568"
     },
     "user_tz": -540
    },
    "id": "zo_5IVJDRqe2",
    "outputId": "22faba1d-1d5f-4177-d06c-a0c230489186"
   },
   "outputs": [],
   "source": [
    "# モデルを宣言する\n",
    "model_2 = mlp_net_2()\n",
    "\n",
    "# 学習させ、その結果を表示する\n",
    "acc, loss = train(model_2, train_loader)\n",
    "print(f'正答率: {acc}, 損失: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-PqywSvzSEvM"
   },
   "source": [
    "- ```\n",
    "正答率： {90.0前後}, 損失: {0.00025前後}\n",
    "```\n",
    "と表示されていれば成功だ。\n",
    "- 恐らく、例題よりも正答率は下がり、損失は大きくなったのではないだろうか。  \n",
    "このように、ハイパーパラメータは学習に大きく影響するということを覚えておこう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "foTqDLiCk2g5"
   },
   "source": [
    "## test()関数の実装\n",
    "次は、テストデータを使った評価を行う`test()`関数を実装する。  `train()`関数から「損失計算」や「最適化」の要素を取り除こう。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FP4c6sieZfOj"
   },
   "outputs": [],
   "source": [
    "# test関数の実装\n",
    "\n",
    "## モデルの予測結果を出力する\n",
    "## ここでいう予測結果とは、確率ベクトルではなく、予測された「値」だ。\n",
    "## バッチごとに出力するので実際はバッチサイズだけ要素をもつテンソルになる\n",
    "def predict(model, batch_imgs):\n",
    "    outputs = model(batch_imgs.reshape(-1, 28*28*1))\n",
    "    _, pred_labels = torch.max(outputs, axis=1)\n",
    "    return pred_labels\n",
    "\n",
    "# test()の実装\n",
    "def test(model, data_loader):\n",
    "    # モデルを評価モードにする\n",
    "    model.eval()\n",
    "    # 正しい予測数、全体のデータ数を数えるカウンターの0初期化\n",
    "    total_data_len = 0\n",
    "    total_correct = 0\n",
    "    for batch_imgs, batch_labels in data_loader:\n",
    "        # 順伝播（=予測）\n",
    "        pred_labels = predict(model, batch_imgs)\n",
    "        # 集計\n",
    "        batch_size = len(pred_labels)\n",
    "        for i in range(batch_size):\n",
    "            total_data_len += 1\n",
    "            if pred_labels[i] == batch_labels[i]:\n",
    "                total_correct += 1\n",
    "    acc = 100.0 * total_correct/total_data_len\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHTpEKJBNK3p"
   },
   "source": [
    "【例題】 学習させた`mlp_net`と`test_loader`を使って、テストを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3551,
     "status": "ok",
     "timestamp": 1590399812008,
     "user": {
      "displayName": "hiro ino",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GihSdoqMmcaSzIVlnJIdtCgZPtPBEFqr0Y3_Cyp=s64",
      "userId": "16665494520159410568"
     },
     "user_tz": -540
    },
    "id": "DDAwyPSSkQH-",
    "outputId": "c2a75331-3b28-4a87-8268-736b50e2cbd2"
   },
   "outputs": [],
   "source": [
    "test_acc = test(model, test_loader)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DH5RIZMhNefA"
   },
   "source": [
    "- 正答率がおよそ`95%`前後になれば成功だ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y-o__UlokU1f"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "6_モデルの学習.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
