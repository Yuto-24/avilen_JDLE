{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oxm6Q9AZJTMO"
   },
   "source": [
    "# Tensorとは？\n",
    "---\n",
    "\n",
    "前単元の復習にもなるが、再度Tensor型の特徴を紹介する。\n",
    "\n",
    "1. TensorはNumPyのndarrayに似ている\n",
    "2. GPUを使って演算を行うことが可能\n",
    "3. 自動微分という機能がある\n",
    "\n",
    "前単元では、特徴1にあたる、`Tensor`と`numpy.ndarray`の共通点などを学習した。  \n",
    "本単元では`numpy.ndarray`ではできない、`Tensor`の特徴**2**と**3**を順に学んでいこう！\n",
    "\n",
    "---\n",
    "## この単元の目標\n",
    "\n",
    "* TensorのGPU演算について知る\n",
    "* Tensorの自動微分機能を学ぶ\n",
    "\n",
    "  → **Tensor型の特徴を勉強していこう**  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JDQ49EgJTMP"
   },
   "outputs": [],
   "source": [
    "# pytorchライブラリのインポート\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmfpcCg538bx"
   },
   "source": [
    "#### CPUとGPUについて\n",
    "---\n",
    "\n",
    "ハードウェアにはそれぞれ得意な計算の種類がある。  \n",
    "それぞれの得意分野は以下の通りだ。\n",
    "\n",
    "* if文のような条件分岐が多い複雑な計算は**CPU**\n",
    "* for文のような繰り返しが多い単純な計算は**GPU**\n",
    "\n",
    "DL(ディープラーニング)の計算では行列の積和を多く扱う。  \n",
    "この計算はfor文が多い単純な計算に当たるため、DLの演算は**GPU**と相性がよい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCvf7OquJTMS"
   },
   "source": [
    "## GPU対応\n",
    "---\n",
    "\n",
    "特徴2：Tensorは**GPUを使って演算を行うことが可能**\n",
    "* DLの計算はGPUを使うことで圧倒的なパフォーマンスを発揮することができる\n",
    "    * PyTorchはCPU/GPU切替可能\n",
    "    * NumpyはGPU非対応\n",
    "\n",
    "\n",
    "実際にプログラムを実行してTensor型のデータを作成しイメージを掴もう！\n",
    "\n",
    "---\n",
    "**※注意※** 本章の例題はGPU環境を整えてから出ないと動かない。  \n",
    "実行すると「GPUが利用できる環境が整っていません」とでる場合がほとんどだろう。  \n",
    "本講座ではGPU環境の構築については扱わないため、構築されていればこのように動くのだろうなと感じつつ説明文を読み学んでほしい。\n",
    "\n",
    "【例題】下記のプログラムを実行して、CPUからGPUデバイスへの切り替えをしてみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1840,
     "status": "ok",
     "timestamp": 1590230156941,
     "user": {
      "displayName": "Kurusu Yuugo",
      "photoUrl": "",
      "userId": "00117977046560544733"
     },
     "user_tz": -540
    },
    "id": "VEOZTuPnJTMS",
    "outputId": "57f12c3e-723d-47ad-8188-f060b8d68605"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    gpu = torch.device(\"cuda\")  # GPUデバイスオブジェクトの作成\n",
    "    cpu = torch.device(\"cpu\")  # CPUデバイスオブジェクトの作成\n",
    "    data1 = torch.zeros((2, 2), device=gpu)  # GPU上に作成\n",
    "    data_cpu = data1.to(cpu)  # CPUへ転送\n",
    "    data_gpu = data_cpu.to(gpu)  # GPUへ転送\n",
    "    print(data_cpu)\n",
    "    print(data_gpu)\n",
    "else:\n",
    "    print(\"GPUが利用できる環境が整っていません\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "977cFTnqJTMV"
   },
   "source": [
    "- ```\n",
    "tensor([[0., 0.],\n",
    "        [0., 0.]])\n",
    "tensor([[0., 0.],\n",
    "        [0., 0.]], device='cuda:0')\n",
    "```\n",
    "環境が整っている場合、上記のように表示される。\n",
    "---\n",
    "1行目のif文はGPUが利用できる環境が構築されているか判断する関数だ\n",
    "\n",
    "上記のような手順で、データをいつでも任意のデバイスへ転送することができる。  \n",
    "また、GPU上にデータが存在するTensorを出力した場合、`device='cuda:0'`と出力されることがわかる。\n",
    "\n",
    "* GPUのデバイスオブジェクトの作成：`torch.device(\"cuda\")`\n",
    "* CPUのデバイスオブジェクトの作成：`torch.device(\"cpu\")`\n",
    "\n",
    "* デバイス間の転送方法：`Tensor名.to(転送先デバイスオブジェクト)`\n",
    "\n",
    "\n",
    "\n",
    "* テンソルをGPU上に作成したい場合はオプション`device`を指定する\n",
    "    * `device=GPUのデバイスオブジェクト`    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6D9uBIBFJTMY"
   },
   "source": [
    "## 自動微分1\n",
    "---\n",
    "特徴3：Tensorには**自動微分という機能がある**\n",
    "* Tensor同士の計算は全て記録している\n",
    "* この機能により、DLプログラムが非常に簡単になる\n",
    "\n",
    "自動微分機能を体験してみよう！\n",
    "まずは、Tensor同士の計算をしてみよう！\n",
    "\n",
    "---\n",
    "【例題】Tensor同士の計算を行う。プログラムを実行して実行結果から挙動を確かめよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 877,
     "status": "ok",
     "timestamp": 1590603651212,
     "user": {
      "displayName": "Kurusu Yuugo",
      "photoUrl": "",
      "userId": "00117977046560544733"
     },
     "user_tz": -540
    },
    "id": "LASCCShiJTMZ",
    "outputId": "c3ddd93d-b36a-4dd4-aa19-f074f0fb6fd5"
   },
   "outputs": [],
   "source": [
    "a = torch.ones(3)\n",
    "b = torch.rand(3)\n",
    "print(a)\n",
    "print(b)\n",
    "print(a+3)\n",
    "print(a*3)\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zCgCQx8KJTMb"
   },
   "source": [
    "---\n",
    "Tensor同士の計算は以上のように行うことができる。\n",
    "\n",
    "**注意点**\n",
    "* 形の異なるTensor同士は計算できない\n",
    "* CPU上のデータとGPU上のデータは計算することができない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wuS05lkTJTMe"
   },
   "source": [
    "## 自動微分2\n",
    "---\n",
    "それでは、自動微分機能を体験してみよう！\n",
    "\n",
    "---\n",
    "【例題1】自動微分機能を体験しよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 895,
     "status": "ok",
     "timestamp": 1590603655298,
     "user": {
      "displayName": "Kurusu Yuugo",
      "photoUrl": "",
      "userId": "00117977046560544733"
     },
     "user_tz": -540
    },
    "id": "Pp04KX6rJTMe",
    "outputId": "893d699c-3030-414f-9aa1-1aeae045cfc5"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(1.0, requires_grad = True)\n",
    "a, b = 3, 5\n",
    "y = a*x + b\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_XOzeFN-JTMg"
   },
   "source": [
    "---\n",
    "* 自動微分機能を利用したい場合は**Tensor**の宣言時に、オプション`requires_grad`を指定する\n",
    "    * `requires_grad=True`  \n",
    "        * `True`にすることで計算の追跡(記録)をするよう設定できる\n",
    "    * 今回は要素をスカラーで値を1としたが、行列でも良いし中身の値も何でも良い。(微分には関係ない)\n",
    "\n",
    "\n",
    "\n",
    "上記のプログラムでは\n",
    "$$ y = 3x + 5 $$\n",
    "の`x=1`のときの出力を表してるので`y=8`\n",
    "\n",
    "* `grad_fn=<AddBackward0>`は`y`が足し算により算出されたということを示している。\n",
    "\n",
    "---\n",
    "【例題2】自動微分機能を体験するためTensorの演算を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIL4han0JTMh"
   },
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9FSf_HZ1JTMj"
   },
   "source": [
    "---\n",
    "何も出力されないが、`計算後のTensor名.backward()`で微分が行われた。  \n",
    "以下のプログラムを動かして確認してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 922,
     "status": "ok",
     "timestamp": 1590603660101,
     "user": {
      "displayName": "Kurusu Yuugo",
      "photoUrl": "",
      "userId": "00117977046560544733"
     },
     "user_tz": -540
    },
    "id": "7mjiLV_mJTMj",
    "outputId": "fb6c0f4e-12da-44d6-a3d4-db415f3fad62"
   },
   "outputs": [],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EDXm52-HJTMl"
   },
   "source": [
    "---\n",
    "* `Tensor名.grad`とすることでその変数名の勾配（微分値）がわかる。\n",
    "* yの式をxで微分すると勾配は3になる。\n",
    "$$ \\frac{dy}{dx} = 3 $$\n",
    "\n",
    "* **Tensor**で宣言されていない変数は微分できないので注意\n",
    "    * 上記のプログラムのままでは`a.grad`や`b.grad`は不可能\n",
    "* この特徴を利用することで、DLのプログラムを楽に構成できるぞ！\n",
    "\n",
    "【注意】  \n",
    "自動微分を利用する上で気をつけてほしいポイントがある。以下のプログラムを何度か実行してみてほしい。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 841,
     "status": "ok",
     "timestamp": 1590603664732,
     "user": {
      "displayName": "Kurusu Yuugo",
      "photoUrl": "",
      "userId": "00117977046560544733"
     },
     "user_tz": -540
    },
    "id": "XXk3r6idOi3X",
    "outputId": "8427e543-7b36-4e4a-a7ba-0a13fc5f7d40"
   },
   "outputs": [],
   "source": [
    "y = a*x + b\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_iTfG9ZwOfbl"
   },
   "source": [
    "勾配が累積されていることがわかるだろうか？  \n",
    "`backward()`が実行されるたびに`Tensor名.grad`は加算を繰り返してしまう。\n",
    "\n",
    "そのため、ループ文を利用して何度も利用する際には、  \n",
    "`backward()`の前に**勾配の初期化**という作業が必要になるぞ！(詳しくは単元6にて)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldrIUxdrJTMm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_Tensor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
